{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Geração de Texto</h2>\n",
    "\n",
    "Alunos: Everton Thomas e Gustavo Reichelt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Prediction</h2>\n",
    "\n",
    "Um modelo pode ser gerado de uma maneira para produzir predições na forma de texto, bastante acuradas, usando algumas sequências de palavras que foram encontradas no modelo treinado.\n",
    "\n",
    "Neste trabalho iremos gerar litetura a partir de uma base treinada com a obra Dom Casmurro de Machado de Assis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "text = (open(\"bv00180a.txt\").read())\n",
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mapeamento de palavras</h2>\n",
    "\n",
    "Neste passo, estamos mapeando cada palavra em uma representação númerica. Este processo é muito importante, pois os algoritimos lidam muito melhor com numeros do que com palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word mapping\n",
    "characters = sorted(list(set(text)))\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing\n",
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])\n",
    "\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Modelo</h2>\n",
    "\n",
    "Resolvemos construir um modelo sequenciando com duas camadas de LSTM com 120 unidades cada, neste modelo resolvemos utilizar apenas 50 epocas, em função do tempo para compilar o modelo.\n",
    "\n",
    "Para melhores resultados podemos aumentar tanto o número das lSTM, quanto a quantidade de epocas, o que vai exigir maior tempo de processamento para gerar o modelo.\n",
    "\n",
    "Após processado o modelo, salvamos no arquivo, text_generator.h5, para que não precise esperar compilar o modelo para visualizar a execução do algoritimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# model.fit(X_modified, Y_modified, epochs=100, batch_size=50)\n",
    "\n",
    "# saving model to use whithout need of compile it every time\n",
    "\n",
    "# model.save_weights('text_generator.h5')\n",
    "model.load_weights('text_generator.h5')\n",
    "# in this notebook will use a pre generate model, for better results increase LSTM and number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gerando texto</h2>\n",
    "\n",
    "A partir de uma linha qualquer, estamos usando o algoritimo para gerar texto com o que o modelo aprendeu apos ler a obra de Machado de Assis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ui do bairro, que eu conheço de vista e de chapéu. cumprimentou-me, sentou-se ao pé de mim,  \r\n",
      "fazer a casa de capitu e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a  \r\n",
      "contertar a casa de capitu e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a minha  \r\n",
      "mãe e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a minha mãe  \r\n",
      "desce a contersação de capitu e a minha mãe e a minha mãe e a minha mãe e a minha mãe  \r\n",
      "de capitu e a minha\n"
     ]
    }
   ],
   "source": [
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]\n",
    "\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "print txt\n",
    "\n",
    "text_file = open(\"Output.txt\", \"w\")\n",
    "text_file.write(txt)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resultado</h2>\n",
    "\n",
    "ui do bairro, que eu conheço de vista e de chapéu. cumprimentou-me, sentou-se ao pé de mim,  \n",
    "fazer a casa de capitu e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a  \n",
    "contertar a casa de capitu e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a minha  \n",
    "mãe e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a minha mãe e a minha mãe  \n",
    "desce a contersação de capitu e a minha mãe e a minha mãe e a minha mãe e a minha mãe  \n",
    "de capitu e a minha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
