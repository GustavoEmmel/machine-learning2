{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Adaboost</h2>\n",
    "\n",
    "Alunos: Everton Thomas, Gustavo Emmel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Boosting</h2>\n",
    "\n",
    "<b><i>Boosting</i></b> é uma abordagem utilizada para prover uma melhor performance para algoritmos clássicos de classificação e regressão. Apesar de poder ser aplicada sobre diversos algoritmos, a abordagem de <i>boosting</i> é comumente utilizada com algoritmos modelados no formato de árvore (árvores de decisão).\n",
    "\n",
    "Em suma, a técnica de <b><i>boosting</i></b> consiste em um conjunto (<i>ensemble</i>) de algoritmos ditos fracos (com performance ligeiramente superior a 50%) que quando combinados, permitem por vezes performances superiores a um aloritmo dito \"forte\", como SVM ou RNA.\n",
    "\n",
    "<h2>Algoritmo AdaBoost</h2>\n",
    "\n",
    "O princípio por trás do <b>AdaBoost</b> é utilizar diversos algoritmos com poder de predição ligeiramente superior à uma escolha aleatória, executados repetidamente sobre o conjunto de dados. A cada iteração, cada instância recebe um peso de acordo com o resultado da predição anterior: o peso é incrementado caso o último algoritmo tenha classificado a instância incorretamente e decrementado caso contrário.\n",
    "\n",
    "Portanto, as instâncias que foram anteriormente classificadas incorretamente recebem maior atenção quando o próximo algoritmo da iteração for executado. Ao final, o algoritmo soma as predições ponderadas de cada iteração, selecionado a classificação correta para as instâncias através de voto majoritário.\n",
    "\n",
    "O algoritmo AdaBoost é apresentado a seguir:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementação do AdaBoost em Python</h2>\n",
    "\n",
    "Vamos implementar o algoritmo em uma classe a parte, permitindo uma melhor separação do código e posterior utilização do AdaBoost na fase de validação cruzada. Para isso, criamos uma classe nos moldes dos classificadores da biblioteca <b>SciKit Learn</b>, ou seja, com os métodos <b>fit</b> e <b>predict</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Adaboost:\n",
    "    \n",
    "    def __init__(self, T):\n",
    "        \"\"\"\n",
    "        Implementação de boosting para classificadores\n",
    "        \n",
    "        Parâmetros:\n",
    "            \n",
    "            T = Array de classificadores\n",
    "        \"\"\"\n",
    "        self.T = T\n",
    "        self.alphas = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Treina os modelos\n",
    "        \n",
    "        Parâmetros:\n",
    "            \n",
    "            X = Dados de treino\n",
    "            \n",
    "            y = Labels de treino\n",
    "            \n",
    "        Retorno:\n",
    "        \n",
    "            predicted = Resultado da predição (y)\n",
    "        \"\"\"\n",
    "        \n",
    "        #inicializa os pesos\n",
    "        weights = np.ones(len(X)) / float(len(X))\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        alphas = []\n",
    "        fit_predicted = np.zeros(len(y))\n",
    "        \n",
    "        #para cada classificador\n",
    "        for clf in self.T:\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            clf.fit(X, y, sample_weight=weights)\n",
    "            \n",
    "            predicted = clf.predict(X)\n",
    "            \n",
    "            miss = [int(d) for d in (predicted != y)]\n",
    "            err   = np.dot(weights, miss)/np.sum(weights)\n",
    "            alpha = 0.5 * np.log((1 - err)/err)\n",
    "            \n",
    "            #guarda o alpha para o classificador\n",
    "            alphas.append(alpha)\n",
    "            \n",
    "            #ajusta os pesos\n",
    "            weights = np.multiply(weights, np.exp([alpha * float(x) for x in miss]))/float(weights.sum())\n",
    "            \n",
    "            accuracy = sum([int(d) for d in (predicted == y)]) / len(predicted)\n",
    "            \n",
    "            fit_predicted = [sum(x) for x in zip(fit_predicted, [x * alpha for x in predicted])]\n",
    "        \n",
    "        self.alphas = alphas\n",
    "        \n",
    "        return np.sign(fit_predicted)\n",
    "        \n",
    "    def predict(self, X):#, y):\n",
    "        \"\"\"\n",
    "        Faz a predição sobre um conjunto de dados\n",
    "        \n",
    "        Parâmetros:\n",
    "        \n",
    "            X = Dados a serem preditos\n",
    "            \n",
    "        Retorno:\n",
    "        \n",
    "            predicted = Resultado da predição (y)\n",
    "        \"\"\"\n",
    "        predicted = np.zeros(len(X))\n",
    "        \n",
    "        for model, alpha in zip(self.T, self.alphas):\n",
    "            \n",
    "            pred = model.predict(X)\n",
    "            \n",
    "            #accuracy = sum([int(d) for d in (pred == y)]) / len(pred)\n",
    "            \n",
    "            #print(accuracy)\n",
    "            \n",
    "            predicted = [sum(x) for x in zip(predicted, [x * alpha for x in pred])]\n",
    "            \n",
    "        predicted = np.sign(predicted)\n",
    "        \n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Explicando o algoritmo</h2>\n",
    "\n",
    "Inicialmente a classe <b>Adaboost</b> deve ser inicializada com uma lista de algoritmos que serão utilizados durante o processo.\n",
    "\n",
    "```\n",
    "clfs =[]\n",
    "clfs.append(DecisionTreeClassifier(criterion='entropy', max_depth=1))\n",
    "clfs.append(DecisionTreeClassifier(criterion='entropy', max_depth=1))\n",
    "clfs.append(DecisionTreeClassifier(criterion='entropy', max_depth=1))\n",
    "\n",
    "model = Adaboost(clfs)\n",
    "```\n",
    "\n",
    "A quantidade de algoritmos presentes nessa lista é que irá determinar quantas vezes ocorrerá o processo <i>predição -> ajuste de peso</i>. No exemplo imediatamente anterior, são adicionados três classificadores do tipo Árvore de Decisão com profundidade 1, também conhecidas como Decision Stump. Isso significa que serão realizadas 3 iterações, com ajuste de peso das instâncias entre cada iteração.\n",
    "\n",
    "```\n",
    "#para cada classificador\n",
    "for clf in self.T:\n",
    "            \n",
    "    clf.fit(X, y, sample_weight=weights)\n",
    "            \n",
    "    predicted = clf.predict(X)\n",
    "            \n",
    "    miss = [int(d) for d in (predicted != y)]\n",
    "    err   = np.dot(weights, miss)/np.sum(weights)\n",
    "    alpha = 0.5 * np.log((1 - err)/err)\n",
    "            \n",
    "    #ajusta os pesos\n",
    "    weights = np.multiply(weights, np.exp([alpha * float(x) for x in miss]))/float(weights.sum())\n",
    "            \n",
    "    fit_predicted = [sum(x) for x in zip(fit_predicted, [x * alpha for x in predicted])]\n",
    "```\n",
    "\n",
    "De forma resumida, em cada iteração é realizado o processo de treinamento do modelo em questão. Após o treinamento, é calculado a taxa de erro (<i>err</i>) que é utilizada para calcular a taxa de atualização dos pesos (<i>alpha</i>).\n",
    "\n",
    "Para instâncias preditas corretamente, o peso desta é decrementado com base no <i>alpha</i> calculado. O contrário ocorre com instâncias preditas incorretamente, as quais terão maior prioridade na próxima iteração.\n",
    "\n",
    "Ao final, as predições geradas por todos os classificadores são somadas e a classe para cada instância é decidida pelo voto majoritário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utilizando o algoritmo AdaBoost</h2>\n",
    "\n",
    "Para testar o algoritmo, utilizamos o <i>dataset</i> [sonnar.all.data](https://www.kaggle.com/ypzhangsam/sonaralldata) que possui dados de varreduras de sonares para identificação de minas.\n",
    "\n",
    "É um problema de classificação binária, onde o objetivo é classificar cada instância como Rocha ou Mina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sonar.all-data.csv', delimiter=',', header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o processo de aplicação do Adaboost, alteramos as classes das instâncias trocando-as:\n",
    "\n",
    "Classe R -> -1\n",
    "Classe M ->  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,-1] = [-1 if x == 'R' else 1 for x in df.iloc[:, -1]]\n",
    "\n",
    "df.iloc[:,-1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o dataframe está carregado e com os labels ajustados, separamos 20% dos dados para teste e utilizamos 80% para treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split, StratifiedKFold\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df.iloc[:,-1], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Validação</h2>\n",
    "\n",
    "Para validação de nosso algoritmo AdaBoost, vamos utilizar o método Cross Validation com 10-folds. Este método permite avaliar a capacidade de generalização de nosso modelo preditivo.\n",
    "\n",
    "Também vamos iterar entre um intervalo para avaliar a performance de nosso algoritmo ao incrementarmos a quantidade de classificadores.\n",
    "\n",
    "Para tal, usaremos como classificador uma Decision Stump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree             import DecisionTreeClassifier\n",
    "from sklearn.metrics          import accuracy_score\n",
    "\n",
    "n_folds = 10\n",
    "n_clfs = 40\n",
    "\n",
    "clfs = []\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "max_idx_accur = 0\n",
    "\n",
    "#armazena o melhor modelo do treinamento\n",
    "best_model = None\n",
    "\n",
    "for i in range(1,n_clfs + 1, 1):\n",
    "    clfs.append(DecisionTreeClassifier(criterion='entropy', max_depth=1))\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    boosting = Adaboost(clfs.copy())\n",
    "    \n",
    "    acc_cv = []\n",
    "    \n",
    "    #Cross-validation\n",
    "    for train_idx, test_idx in kf.split(train, train.iloc[:, -1]):\n",
    "        \n",
    "        X_train, y_train = df.iloc[train_idx, :-1], df.iloc[train_idx, -1]\n",
    "        X_test , y_test  = df.iloc[test_idx , :-1], df.iloc[test_idx, -1]\n",
    "    \n",
    "        pred = boosting.fit(X_train, y_train)\n",
    "        \n",
    "        pred_test = boosting.predict(X_test)\n",
    "        \n",
    "        acc_cv.append(accuracy_score(y_test, pred_test))\n",
    "    \n",
    "    if len(accuracy) == 0 or np.mean(acc_cv) > max(accuracy):\n",
    "        max_idx_accur = i\n",
    "        best_model = boosting\n",
    "    \n",
    "    accuracy.append(np.mean(acc_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E como nosso modelo se saiu no treinamento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1d60840d5f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d6068dfcc0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8)) \n",
    "ax  = fig.add_subplot(111)\n",
    "\n",
    "ax.set_title('Performance on trainning with 10-fold validation')\n",
    "ax.plot(range(1, len(accuracy) + 1), accuracy, '-b')\n",
    "ax.set_xlabel('Number of estimators')\n",
    "ax.set_xticks(np.arange(1, len(accuracy) +1, len(accuracy) / 10))\n",
    "ax.set_yticks(np.arange(min(accuracy), max(accuracy), 0.025))\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.axhline(max(accuracy), linestyle='--', color='red', linewidth=1)\n",
    "plt.axvline(max_idx_accur, linestyle='--', color='red', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar que há um acréscimo na performance conforme aumentamos a quantidade de Decision Stumps. O melhor modelo encontrado em um intervalo de 1 a 40 classificadores foi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Acurácia no treinamento 0.7899754901960785, com 33 classificadores.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Acurácia no treinamento {}, com {} classificadores.\".format(max(accuracy), max_idx_accur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Aplicando sobre os dados de teste</h2>\n",
    "\n",
    "Agora vamos aplicar nosso melhor modelo (33 classificadores) sobre os dados de teste que separamos anteriormente (20% do dataset).\n",
    "\n",
    "Mas antes vamos criar nossas próprias funções de cálculo de <i>recall</i>, <i>precision</i> e <i>f1-score</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall_score(true_y, pred_y, pos_label):\n",
    "    tp = 0.\n",
    "    fn = 0.\n",
    "    \n",
    "    for ty, py in zip(true_y, pred_y):\n",
    "        if ty == pos_label and ty == py:\n",
    "            tp += 1\n",
    "        elif ty == pos_label and ty != py:\n",
    "            fn += 1\n",
    "            \n",
    "    return tp / (tp + fn)\n",
    "    \n",
    "def calc_precision_score(true_y, pred_y, pos_label):\n",
    "    tp = 0.\n",
    "    fp = 0.\n",
    "    \n",
    "    for ty, py in zip(true_y, pred_y):\n",
    "        if (ty == pos_label and ty == py):\n",
    "            tp += 1\n",
    "        elif (py == pos_label and ty != py):\n",
    "            fp += 1\n",
    "            \n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def calc_f1_score(true_y, pred_y, pos_label):\n",
    "    precision = calc_precision_score(true_y, pred_y, pos_label)\n",
    "    recall = calc_recall_score(true_y, pred_y, pos_label)\n",
    "    \n",
    "    return 2* (precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim...Vamos aplicar nosso modelo sobre os dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Aplicando o melhor modelo sobre os dados de teste \n",
      "-------------------------------------------------\n",
      "> Classificadores:  33\n",
      "> Acurácia.......:  0.8333333333333334\n",
      "-------------------------------------------------\n",
      "> Classe M (1): \n",
      "\t> Recall:  0.7272727272727273  / Precision:  0.9411764705882353\n",
      "> Classe R (-1): \n",
      "\t> Recall:  0.95  / Precision:  0.76\n",
      "-------------------------------------------------\n",
      "F1 Score:  0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "predicted = boosting.predict(test_X)\n",
    "\n",
    "accuracy_test = accuracy_score(test_y, predicted)\n",
    "\n",
    "rM = calc_recall_score(test_y, predicted, pos_label=1)\n",
    "rR = calc_recall_score(test_y, predicted, pos_label=-1)\n",
    "pM = calc_precision_score(test_y, predicted, pos_label=1)\n",
    "pR = calc_precision_score(test_y, predicted, pos_label=-1)\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print('Aplicando o melhor modelo sobre os dados de teste ')\n",
    "print('-------------------------------------------------')\n",
    "print('> Classificadores: ', len(best_model.T))\n",
    "print('> Acurácia.......: ', accuracy_test)\n",
    "print('-------------------------------------------------')\n",
    "print('> Classe M (1): ')\n",
    "print('\\t> Recall: ', rM, ' / Precision: ', pM)\n",
    "print('> Classe R (-1): ')\n",
    "print('\\t> Recall: ', rR, ' / Precision: ', pR)\n",
    "print('-------------------------------------------------')\n",
    "print('F1 Score: ', calc_f1_score(test_y, predicted, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Análise</h2>\n",
    "\n",
    "Verificamos que nosso modelo obteve uma acurácia superior a encontrada durante o treinamento.\n",
    "\n",
    "Entretanto, as diferenças entre Precision e Recall para a classe M preocupam. Pelo Recall em 0.72, podemos inferir que ocorreram muitos Falso Negativos, ou seja, muitas Minas foram classificadas como Rochas.\n",
    "\n",
    "A métrica Precision para a classe R acaba confirmando a afirmação anterior: 76% indica que ocorreram muitos Falso Positivos, ou seja, muitas Minas que foram classificadas como Rochas.\n",
    "\n",
    "Também trouxemos a métrica F1 Score, como forma de simplificar a avaliação do modelo. Com base nessa métrica, podemos verificar que, mesmo assim, obtemos um modelo razoável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Comparando com outro modelo \"sem boosting\"</h2>\n",
    "\n",
    "Para finalizar, vamos comparar nosso AdaBoost com um modelo sem utilização de <i>boosting</i>, no caso um SVM.\n",
    "\n",
    "Para efeitos de comparação, manteremos a validação cruzada em 10-fols e a mesma amostra de treino e teste (80/20) utilizada no AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "       Aplicando SVM os dados de teste \n",
      "-------------------------------------------------\n",
      "> Acurácia.......:  0.5476190476190477\n",
      "-------------------------------------------------\n",
      "> Classe M (1): \n",
      "\t> Recall:  0.13636363636363635  / Precision:  1.0\n",
      "> Classe R (-1): \n",
      "\t> Recall:  1.0  / Precision:  0.5128205128205128\n",
      "-------------------------------------------------\n",
      "F1 Score:  0.24000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    \n",
    "#Cross-validation\n",
    "for train_idx, test_idx in kf.split(train, train.iloc[:, -1]):\n",
    "\n",
    "    X_train, y_train = df.iloc[train_idx, :-1], df.iloc[train_idx, -1]\n",
    "    X_test , y_test  = df.iloc[test_idx , :-1], df.iloc[test_idx, -1]\n",
    "\n",
    "    pred = model.fit(X_train, y_train)\n",
    "\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "test_X, test_y = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "predicted = model.predict(test_X)\n",
    "\n",
    "accuracy_test = accuracy_score(test_y, predicted)\n",
    "\n",
    "rM = calc_recall_score(test_y, predicted, pos_label=1)\n",
    "rR = calc_recall_score(test_y, predicted, pos_label=-1)\n",
    "pM = calc_precision_score(test_y, predicted, pos_label=1)\n",
    "pR = calc_precision_score(test_y, predicted, pos_label=-1)\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print('       Aplicando SVM os dados de teste ')\n",
    "print('-------------------------------------------------')\n",
    "print('> Acurácia.......: ', accuracy_test)\n",
    "print('-------------------------------------------------')\n",
    "print('> Classe M (1): ')\n",
    "print('\\t> Recall: ', rM, ' / Precision: ', pM)\n",
    "print('> Classe R (-1): ')\n",
    "print('\\t> Recall: ', rR, ' / Precision: ', pR)\n",
    "print('-------------------------------------------------')\n",
    "print('F1 Score: ', calc_f1_score(test_y, predicted, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Análise AdaBoost x SVM</h2>\n",
    "\n",
    "Podemos verificar que o AdaBoost obteve valores de acurácia e F1-Score superiores ao SVM, quando na sua configuração default (C=1, gamma='auto').\n",
    "\n",
    "Porém, quando ajustamos os parâmetros do SVM conseguimos obter uma performance ligeiramente superior ao AdaBoost:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "       Aplicando SVM os dados de teste \n",
      "-------------------------------------------------\n",
      "> Acurácia.......:  0.8571428571428571\n",
      "-------------------------------------------------\n",
      "> Classe M (1): \n",
      "\t> Recall:  0.7272727272727273  / Precision:  1.0\n",
      "> Classe R (-1): \n",
      "\t> Recall:  1.0  / Precision:  0.7692307692307693\n",
      "-------------------------------------------------\n",
      "F1 Score:  0.8421052631578948\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=50, gamma=0.1)\n",
    "\n",
    "#Cross-validation\n",
    "for train_idx, test_idx in kf.split(train, train.iloc[:, -1]):\n",
    "\n",
    "    X_train, y_train = df.iloc[train_idx, :-1], df.iloc[train_idx, -1]\n",
    "    X_test , y_test  = df.iloc[test_idx , :-1], df.iloc[test_idx, -1]\n",
    "\n",
    "    pred = model.fit(X_train, y_train)\n",
    "\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "test_X, test_y = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "predicted = model.predict(test_X)\n",
    "\n",
    "accuracy_test = accuracy_score(test_y, predicted)\n",
    "\n",
    "rM = calc_recall_score(test_y, predicted, pos_label=1)\n",
    "rR = calc_recall_score(test_y, predicted, pos_label=-1)\n",
    "pM = calc_precision_score(test_y, predicted, pos_label=1)\n",
    "pR = calc_precision_score(test_y, predicted, pos_label=-1)\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "print('       Aplicando SVM os dados de teste ')\n",
    "print('-------------------------------------------------')\n",
    "print('> Acurácia.......: ', accuracy_test)\n",
    "print('-------------------------------------------------')\n",
    "print('> Classe M (1): ')\n",
    "print('\\t> Recall: ', rM, ' / Precision: ', pM)\n",
    "print('> Classe R (-1): ')\n",
    "print('\\t> Recall: ', rR, ' / Precision: ', pR)\n",
    "print('-------------------------------------------------')\n",
    "print('F1 Score: ', calc_f1_score(test_y, predicted, pos_label=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
